#!/usr/bin/env python3
"""
æµå¼ä¼ è¾“é˜»æ–­é—®é¢˜è°ƒè¯•è„šæœ¬
ç”¨äºæµ‹è¯•å’Œè¯Šæ–­ playground API çš„æµå¼å“åº”é—®é¢˜
"""

import asyncio
import aiohttp
import time
import json
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# æµ‹è¯•é…ç½®
API_BASE_URL = "http://localhost:8001/v1/playground"
TEST_AGENT_ID = "agno_assist"  # æ ¹æ®ä½ çš„é…ç½®è°ƒæ•´
TEST_MESSAGE = "è¯·è§£é‡Šä¸€ä¸‹çˆ±å› æ–¯å¦çš„è´¨èƒ½æ–¹ç¨‹ E=mcÂ²ï¼Œå¹¶ç”¨LaTeXå…¬å¼å±•ç¤ºã€‚"

async def test_streaming_response():
    """æµ‹è¯•æµå¼å“åº”ï¼Œç›‘æ§æ½œåœ¨çš„é˜»æ–­é—®é¢˜"""
    
    url = f"{API_BASE_URL}/agents/{TEST_AGENT_ID}/runs"
    
    # æ„å»ºFormData
    data = aiohttp.FormData()
    data.add_field('message', TEST_MESSAGE)
    data.add_field('stream', 'true')
    data.add_field('session_id', f'test_session_{int(time.time())}')
    
    logger.info(f"ğŸš€ å¼€å§‹æµå¼è¯·æ±‚: {url}")
    start_time = time.time()
    
    timeout = aiohttp.ClientTimeout(total=300)  # 5åˆ†é’Ÿè¶…æ—¶
    
    try:
        async with aiohttp.ClientSession(timeout=timeout) as session:
            async with session.post(url, data=data) as response:
                if response.status != 200:
                    logger.error(f"âŒ HTTPé”™è¯¯: {response.status}")
                    text = await response.text()
                    logger.error(f"é”™è¯¯å†…å®¹: {text}")
                    return
                
                logger.info(f"âœ… è¿æ¥æˆåŠŸï¼Œå¼€å§‹æ¥æ”¶æµå¼æ•°æ®...")
                
                chunk_count = 0
                last_chunk_time = time.time()
                total_content = ""
                json_buffer = ""  # ç”¨äºç´¯ç§¯JSONæ•°æ®
                json_count = 0
                
                async for line in response.content:
                    if not line:
                        continue
                        
                    chunk_count += 1
                    current_time = time.time()
                    chunk_interval = current_time - last_chunk_time
                    total_elapsed = current_time - start_time
                    
                    try:
                        # å°†æ¥æ”¶åˆ°çš„æ•°æ®æ·»åŠ åˆ°ç¼“å†²åŒº
                        chunk_text = line.decode('utf-8')
                        json_buffer += chunk_text
                        
                        # å°è¯•è§£æå®Œæ•´çš„JSONå¯¹è±¡
                        while True:
                            # æŸ¥æ‰¾å®Œæ•´çš„JSONå¯¹è±¡
                            brace_count = 0
                            json_start = -1
                            json_end = -1
                            
                            for i, char in enumerate(json_buffer):
                                if char == '{':
                                    if json_start == -1:
                                        json_start = i
                                    brace_count += 1
                                elif char == '}':
                                    brace_count -= 1
                                    if brace_count == 0 and json_start != -1:
                                        json_end = i
                                        break
                            
                            if json_start != -1 and json_end != -1:
                                # æ‰¾åˆ°å®Œæ•´çš„JSONå¯¹è±¡
                                json_str = json_buffer[json_start:json_end + 1]
                                json_buffer = json_buffer[json_end + 1:]  # ç§»é™¤å·²å¤„ç†çš„éƒ¨åˆ†
                                
                                try:
                                    chunk_data = json.loads(json_str)
                                    json_count += 1
                                    
                                    content = chunk_data.get('content', '')
                                    event = chunk_data.get('event', 'unknown')
                                    
                                    if content:
                                        total_content += content
                                    
                                    if json_count <= 10 or json_count % 100 == 0:  # åªæ˜¾ç¤ºå‰10ä¸ªå’Œæ¯100ä¸ª
                                        logger.info(f"ğŸ“¦ JSON #{json_count} (chunk #{chunk_count}, é—´éš”: {chunk_interval:.3f}s)")
                                        logger.info(f"   äº‹ä»¶ç±»å‹: {event}")
                                        logger.info(f"   å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
                                        logger.info(f"   ç´¯è®¡å†…å®¹: {len(total_content)} å­—ç¬¦")
                                    
                                    # æ£€æŸ¥æ˜¯å¦åŒ…å«æ•°å­¦å…¬å¼
                                    if any(marker in content for marker in ['$$', '\\[', '\\(', 'E=mc']):
                                        logger.info(f"ğŸ§® æ£€æµ‹åˆ°æ•°å­¦å…¬å¼å†…å®¹ (JSON #{json_count})")
                                        logger.info(f"   å…¬å¼ç‰‡æ®µ: {content[:100]}...")
                                    
                                except json.JSONDecodeError as e:
                                    logger.warning(f"âš ï¸ JSONè§£æå¤±è´¥ (JSON #{json_count}): {e}")
                                    logger.warning(f"JSONå†…å®¹: {json_str[:200]}...")
                            else:
                                # æ²¡æœ‰æ‰¾åˆ°å®Œæ•´çš„JSONå¯¹è±¡ï¼Œç­‰å¾…æ›´å¤šæ•°æ®
                                break
                        
                        # æ£€æµ‹æ½œåœ¨çš„é˜»æ–­
                        if chunk_interval > 10.0:
                            logger.warning(f"âš ï¸ æ£€æµ‹åˆ°æ…¢é€Ÿchunk! é—´éš”: {chunk_interval:.3f}s")
                        
                    except UnicodeDecodeError as e:
                        logger.warning(f"âš ï¸ Unicodeè§£ç å¤±è´¥: {e}")
                    
                    last_chunk_time = current_time
                
                total_time = time.time() - start_time
                logger.info(f"ğŸ‰ æµå¼ä¼ è¾“å®Œæˆ!")
                logger.info(f"   æ€»chunkæ•°: {chunk_count}")
                logger.info(f"   è§£æçš„JSONå¯¹è±¡æ•°: {json_count}")
                logger.info(f"   æ€»æ—¶é—´: {total_time:.3f}s")
                logger.info(f"   å¹³å‡chunké—´éš”: {total_time/max(1, chunk_count):.3f}s")
                logger.info(f"   æœ€ç»ˆå†…å®¹é•¿åº¦: {len(total_content)} å­—ç¬¦")
                logger.info(f"   å‰©ä½™ç¼“å†²åŒº: {len(json_buffer)} å­—ç¬¦")
                
                # æ˜¾ç¤ºæœ€ç»ˆå†…å®¹çš„å‰å‡ è¡Œ
                if total_content:
                    lines = total_content.split('\n')[:5]
                    logger.info(f"ğŸ“„ å†…å®¹é¢„è§ˆ:")
                    for i, line in enumerate(lines, 1):
                        logger.info(f"   {i}: {line[:100]}...")
                
    except asyncio.TimeoutError:
        logger.error("âŒ è¯·æ±‚è¶…æ—¶!")
    except aiohttp.ClientError as e:
        logger.error(f"âŒ å®¢æˆ·ç«¯é”™è¯¯: {e}")
    except Exception as e:
        logger.error(f"âŒ æœªçŸ¥é”™è¯¯: {e}")
        import traceback
        logger.error(traceback.format_exc())

async def test_multiple_requests():
    """æµ‹è¯•å¤šä¸ªè¿ç»­è¯·æ±‚ï¼Œè§‚å¯Ÿæ˜¯å¦æœ‰æ€§èƒ½ä¸‹é™"""
    
    for i in range(3):
        logger.info(f"\n{'='*50}")
        logger.info(f"å¼€å§‹ç¬¬ {i+1} æ¬¡æµ‹è¯•")
        logger.info(f"{'='*50}")
        
        await test_streaming_response()
        
        if i < 2:  # ä¸æ˜¯æœ€åä¸€æ¬¡
            logger.info("â±ï¸ ç­‰å¾…5ç§’åè¿›è¡Œä¸‹ä¸€æ¬¡æµ‹è¯•...")
            await asyncio.sleep(5)

if __name__ == "__main__":
    print("ğŸ” æµå¼ä¼ è¾“è°ƒè¯•è„šæœ¬")
    print("=" * 50)
    
    # å•æ¬¡æµ‹è¯•
    print("\n1. è¿è¡Œå•æ¬¡æµå¼è¯·æ±‚æµ‹è¯•...")
    asyncio.run(test_streaming_response())
    
    # å¤šæ¬¡æµ‹è¯•
    # print("\n2. è¿è¡Œå¤šæ¬¡è¿ç»­æµ‹è¯•...")
    # asyncio.run(test_multiple_requests())